{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8eef39",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "The objective of this assignment is to run ML models and make publication-worthy figures or tables\n",
    "\n",
    "We use the German Credit Risk dataset to answer the questions given in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa0de0",
   "metadata": {},
   "source": [
    "### German Credit Risk Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812a49a",
   "metadata": {},
   "source": [
    "**About dataset**\\\n",
    "The dataset consists of following columns\n",
    "1. **checking_balance**           : Amount of money available in account of customers\n",
    "2. **months_loan_duration**       : Duration since loan taken\n",
    "3. **credit_history**             : credit history of each customers \n",
    "4. **purpose**                    : Purpose why loan has been taken\n",
    "5. **amount**                     : Amount of loan taken\n",
    "6. **savings_balance**            : Balance in account\n",
    "7. **employment_duration**        : Duration of employment\n",
    "8. **percent_of_income**          : Percentage of monthly income\n",
    "9. **years_at_residence**         : Duration of current residence\n",
    "10. **age**                       : Age of customer\n",
    "11. **other_credit**              : Any other credits taken\n",
    "12. **housing**                   : Type of housing, rent or own\n",
    "13. **existing_loans_count**      : Existing count of loans\n",
    "14. **job**                       : Job type\n",
    "15. **dependents**                : Any dependents on customer\n",
    "16. **phone**                     : Having phone or not\n",
    "17. **default**                   : Default status (Target column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e5acb1",
   "metadata": {},
   "source": [
    "#### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "463bd531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\vgjma\\anaconda3\\lib\\site-packages (1.7.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\vgjma\\anaconda3\\lib\\site-packages (from xgboost) (1.25.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\vgjma\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n"
     ]
    }
   ],
   "source": [
    "#install the libraries\n",
    "!pip install xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plot\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "\n",
    "# To get different metric scores, and split data\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c86d44",
   "metadata": {},
   "source": [
    "Create train test split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd0ce3",
   "metadata": {},
   "source": [
    "Run model and see results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "701697ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(model, X, y, test_size=0.2, random_state=42):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get feature importances\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importances = model.feature_importances_\n",
    "        \n",
    "        # Print or visualize feature importances\n",
    "        for feature_name, importance in zip(X.columns, feature_importances):\n",
    "            print(f\"{feature_name}: {importance}\")\n",
    "            \n",
    "        plt.barh(X.columns, feature_importances)\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.show()\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    cls_report = classification_report(y_test, y_pred,  output_dict=True)\n",
    "    return cls_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d5d29",
   "metadata": {},
   "source": [
    "HyperParameter tuning for Gradient Boost and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b4f6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_boosting_hyperparameters(model, X, y, test_size=0.2, random_state=42):\n",
    "     # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    #hyperparameters \n",
    "    grid = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': np.arange(100, 500, 100),\n",
    "        'max_depth': [2, 3, 4, 5, 6, 7]\n",
    "    }\n",
    "\n",
    "    model_cv = GridSearchCV(model, grid, cv=4)\n",
    "    model_cv.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model_cv.predict(X_test)\n",
    "\n",
    "    print(\"Best Parameters:\", model_cv.best_params_)\n",
    "    print(\"Train Score:\", model_cv.best_score_)\n",
    "    print(\"Test Score:\", model_cv.score(X_test, y_test))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    cls_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return cls_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032981c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_voting_classifier(model1, model2, model3, model4, model5, X, y,voting):\n",
    "    # Create the VotingClassifier\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[('gbc', model1), ('bc', model2), ('rf', model3), ('xgb', model4), ('svc', model5)],\n",
    "        voting=voting  # 'hard' for majority vote or 'soft' for weighted probabilities\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # Train the VotingClassifier\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = voting_clf.predict(X_test)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # return classification report\n",
    "    cls_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return cls_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "356a379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_bagging_classifier(X, y, base_classifier=None, random_state=1):\n",
    "    if base_classifier is None:\n",
    "        base_classifier = DecisionTreeClassifier()\n",
    "    \n",
    "    bagging_clf = BaggingClassifier(base_estimator=base_classifier, random_state=random_state)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'max_samples': [0.5, 0.7, 0.9],\n",
    "        'max_features': [0.5, 0.7, 0.9]\n",
    "    }\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    grid_search = GridSearchCV(bagging_clf, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    # return classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    cls_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    return cls_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "824378ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056dd46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
