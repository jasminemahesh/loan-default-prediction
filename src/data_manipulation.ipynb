{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8eef39",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "The objective of this assignment is to manipulate, wrangle, visualize data.\n",
    "\n",
    "We use the German Credit Risk dataset to answer the questions given in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa0de0",
   "metadata": {},
   "source": [
    "### German Credit Risk Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812a49a",
   "metadata": {},
   "source": [
    "**About dataset**\\\n",
    "The dataset consists of following columns\n",
    "1. **checking_balance**           : Amount of money available in account of customers\n",
    "2. **months_loan_duration**       : Duration since loan taken\n",
    "3. **credit_history**             : credit history of each customers \n",
    "4. **purpose**                    : Purpose why loan has been taken\n",
    "5. **amount**                     : Amount of loan taken\n",
    "6. **savings_balance**            : Balance in account\n",
    "7. **employment_duration**        : Duration of employment\n",
    "8. **percent_of_income**          : Percentage of monthly income\n",
    "9. **years_at_residence**         : Duration of current residence\n",
    "10. **age**                       : Age of customer\n",
    "11. **other_credit**              : Any other credits taken\n",
    "12. **housing**                   : Type of housing, rent or own\n",
    "13. **existing_loans_count**      : Existing count of loans\n",
    "14. **job**                       : Job type\n",
    "15. **dependents**                : Any dependents on customer\n",
    "16. **phone**                     : Having phone or not\n",
    "17. **default**                   : Default status (Target column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e5acb1",
   "metadata": {},
   "source": [
    "#### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a985764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\vgjma\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\vgjma\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.11.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vgjma\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\vgjma\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\vgjma\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.25.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\vgjma\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "463bd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Label Encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c81f43",
   "metadata": {},
   "source": [
    "#### Manipulate and Wrangle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2da0f",
   "metadata": {},
   "source": [
    "\n",
    "Impute missing values in the column using a random sampling approach based on the distribution of non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0c519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_data(df, column):\n",
    "    # Impute missing values\n",
    "    value_counts = df[column].value_counts()\n",
    "    print(\"Original value_counts:\\n\", value_counts)\n",
    "    print('\\n')\n",
    "\n",
    "    # Get the distribution of non-missing values\n",
    "    distribution = df[column].value_counts(normalize=True)\n",
    "\n",
    "    print(\"Distribution:\\n\", distribution)\n",
    "    print('\\n')\n",
    "\n",
    "    # Replace missing values based on distribution\n",
    "    missing_indices = df[df[column].isnull()].index\n",
    "    imputed_values = np.random.choice(distribution.index, size=len(missing_indices), p=distribution.values)\n",
    "    df.loc[missing_indices, column] = imputed_values\n",
    "\n",
    "    # Calculate value counts after imputation\n",
    "    value_counts_after = df[column].value_counts()\n",
    "    print(\"Value_counts after imputation:\\n\", value_counts_after)\n",
    "    print('\\n')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c471d55",
   "metadata": {},
   "source": [
    "Merge categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f30329aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_categories(df,column,category1,category2):\n",
    "    value_counts = df[column].value_counts()\n",
    "    print(value_counts)\n",
    "    print('\\n')\n",
    "\n",
    "    df[column] = df[column].replace(category1, category2)\n",
    "\n",
    "    value_counts = df[column].value_counts()\n",
    "    print(value_counts.sort_values(ascending=False))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28ddf7",
   "metadata": {},
   "source": [
    "Visualization : Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f07aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_distribution(df, features):\n",
    "    # Calculate the number of rows and columns needed for subplots\n",
    "    num_rows = (len(features) + 1) // 2\n",
    "    num_cols = 2\n",
    "\n",
    "    # Create a figure and subplots\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 30))\n",
    "\n",
    "    # Flatten the axs array to iterate through subplots\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Iterate through features and create bar plots\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axs[i]\n",
    "        df[feature].value_counts().plot(kind='bar', ax=ax)\n",
    "        ax.set_title(f'{feature} Distribution')\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71875c0",
   "metadata": {},
   "source": [
    "### Wrangling : Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41047b5f",
   "metadata": {},
   "source": [
    "- Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f799669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ordinal_encoding(df, columns, categories_list):\n",
    "    for col, categories in zip(columns, categories_list):\n",
    "        encoder = OrdinalEncoder(categories=[categories])\n",
    "        encoded_values = encoder.fit_transform(df[[col]])\n",
    "        df[f'{col}_encoded'] = encoded_values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e274466a",
   "metadata": {},
   "source": [
    "- Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec489a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_label_encoding(df, columns_to_encode):\n",
    "    for col in columns_to_encode:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d626bf",
   "metadata": {},
   "source": [
    "Relationship of categorical predictor columns with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4bc7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_predictors_to_target(df, categorical_columns):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for col in categorical_columns:\n",
    "        plt.subplot(3, 3, categorical_columns.index(col) + 1)\n",
    "        sns.barplot(x=col, y='default', data=df, ci=None)\n",
    "        plt.title(f'Relationship between {col} and Default')\n",
    "        plt.ylabel('Default Probability')\n",
    "        plt.xlabel(col)\n",
    "        plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('C:\\Jasmine\\GreatLearning\\ML\\project\\GermanBankLoan\\german-bank-loan-defaults\\reports\\figures\\CategoricalFeaturesRelationToTarget.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ac549",
   "metadata": {},
   "source": [
    "Relationship of numeric predictor columns with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96bc00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_predictors_to_target(df, numeric_columns):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for col in numeric_columns:\n",
    "        plt.subplot(3, 3, numeric_columns.index(col) + 1)\n",
    "        sns.boxplot(x='default', y=col, data=df)\n",
    "        plt.title(f'Relationship between {col} and Default')\n",
    "        plt.xlabel('Default')\n",
    "        plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('C:/Jasmine/GreatLearning/project/GermanBankLoan/german-bank-loan-defaults/reports/figures/NumericalFeaturesRelationToTarget.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49329de4",
   "metadata": {},
   "source": [
    "Perform Random Oversampling to improve recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a57f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_oversampling(X, y, random_state=42):\n",
    "    # Count the occurrences of each class before oversampling\n",
    "    class_counts = np.bincount(y)\n",
    "    print(\"Class counts before oversampling:\", class_counts)\n",
    "\n",
    "    # Create an instance of RandomOverSampler\n",
    "    oversampler = RandomOverSampler(sampling_strategy=\"minority\", random_state=random_state)\n",
    "\n",
    "    # Perform random oversampling on the data\n",
    "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "    # Count the occurrences of each class after oversampling\n",
    "    resampled_class_counts = np.bincount(y_resampled)\n",
    "    print(\"Class counts after oversampling:\", resampled_class_counts)\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b197b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7c3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
